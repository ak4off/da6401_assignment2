2025-04-15 16:46:31,042 INFO    Thread-3 (_run_job):1042230 [wandb_setup.py:_flush():67] Current SDK version is 0.19.9
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_setup.py:_flush():67] Configure stats pid to 1042230
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_setup.py:_flush():67] Loading settings from /home/speech/.config/wandb/settings
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_setup.py:_flush():67] Loading settings from /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/settings
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug.log
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug-internal.log
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():781] calling init triggers
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 32, 'data_aug': False, 'data_dir': 'data/inaturalist_12K', 'dense_size': 256, 'dropout': 0.1, 'early_stopping_patience': 5, 'epochs': 15, 'freeze_option': 0, 'lr': 5.40352792491126e-05, 'scheduler_patience': 2, 'use_scheduler': True, 'weight_decay': 0.001}
config: {'_wandb': {}}
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():809] starting backend
2025-04-15 16:46:31,043 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():813] sending inform_init request
2025-04-15 16:46:31,044 INFO    Thread-3 (_run_job):1042230 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-15 16:46:31,045 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():823] backend started and connected
2025-04-15 16:46:31,045 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_config_callback():1327] config_cb None None {'batch_size': 32, 'data_aug': False, 'data_dir': 'data/inaturalist_12K', 'dense_size': 256, 'dropout': 0.1, 'early_stopping_patience': 5, 'epochs': 15, 'freeze_option': 0, 'lr': 5.40352792491126e-05, 'scheduler_patience': 2, 'use_scheduler': True, 'weight_decay': 0.001}
2025-04-15 16:46:31,045 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():915] updated telemetry
2025-04-15 16:46:31,048 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():939] communicating run to backend with 90.0 second timeout
2025-04-15 16:46:31,726 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():1014] starting run threads in backend
2025-04-15 16:46:31,752 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_console_start():2454] atexit reg
2025-04-15 16:46:31,753 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-04-15 16:46:31,753 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_redirect():2371] Wrapping output streams.
2025-04-15 16:46:31,753 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_redirect():2394] Redirects installed.
2025-04-15 16:46:31,753 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():1056] run started, returning control to user process
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug.log
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug.log
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug-internal.log
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/wandb/run-20250415_164631-67or1yn3/logs/debug-internal.log
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():781] calling init triggers
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():781] calling init triggers
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 32, 'data_aug': False, 'data_dir': 'data/inaturalist_12K', 'dense_size': 256, 'dropout': 0.1, 'early_stopping_patience': 5, 'epochs': 15, 'freeze_option': 0, 'lr': 5.40352792491126e-05, 'scheduler_patience': 2, 'use_scheduler': True, 'weight_decay': 0.001}
config: {'data_dir': 'data/inaturalist_12K', 'image_size': 224, 'batch_size': 32, 'data_aug': False, 'model': 'resnet50', 'freeze_option': 0, 'dropout': 0.1, 'dense_size': 256, 'epochs': 15, 'lr': 5.40352792491126e-05, 'weight_decay': 0.001, 'log_interval': 10, 'early_stopping_patience': 5, 'use_scheduler': True, 'scheduler_patience': 2, 'save_model_path': './checkpoints/best_model.pt', 'seed': 42, 'use_wandb': True, 'wandb_project': 'finetune_partB_Assgn2', 'wandb_entity': 'ns24z274-iitm-ac-in', 'wandb_run_name': 'clean-sweep-1', '_wandb': {}}
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 32, 'data_aug': False, 'data_dir': 'data/inaturalist_12K', 'dense_size': 256, 'dropout': 0.1, 'early_stopping_patience': 5, 'epochs': 15, 'freeze_option': 0, 'lr': 5.40352792491126e-05, 'scheduler_patience': 2, 'use_scheduler': True, 'weight_decay': 0.001}
config: {'data_dir': 'data/inaturalist_12K', 'image_size': 224, 'batch_size': 32, 'data_aug': False, 'model': 'resnet50', 'freeze_option': 0, 'dropout': 0.1, 'dense_size': 256, 'epochs': 15, 'lr': 5.40352792491126e-05, 'weight_decay': 0.001, 'log_interval': 10, 'early_stopping_patience': 5, 'use_scheduler': True, 'scheduler_patience': 2, 'save_model_path': './checkpoints/best_model.pt', 'seed': 42, 'use_wandb': True, 'wandb_project': 'finetune_partB_Assgn2', 'wandb_entity': 'ns24z274-iitm-ac-in', 'wandb_run_name': 'clean-sweep-1', '_wandb': {}}
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():801] wandb.init() called while a run is active
2025-04-15 16:46:31,762 INFO    Thread-3 (_run_job):1042230 [wandb_init.py:init():801] wandb.init() called while a run is active
2025-04-15 16:46:36,734 INFO    Thread-3 (_run_job):1042230 [wandb_watch.py:_watch():71] Watching
2025-04-15 16:46:36,734 INFO    Thread-3 (_run_job):1042230 [wandb_watch.py:_watch():71] Watching
2025-04-15 16:54:04,697 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_finish():2189] finishing run ns24z274-iitm-ac-in/finetune_partB_Assgn2/67or1yn3
2025-04-15 16:54:04,697 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_finish():2189] finishing run ns24z274-iitm-ac-in/finetune_partB_Assgn2/67or1yn3
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_atexit_cleanup():2419] got exitcode: 0
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_atexit_cleanup():2419] got exitcode: 0
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_restore():2401] restore
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_restore():2401] restore
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_restore():2407] restore done
2025-04-15 16:54:04,700 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_restore():2407] restore done
2025-04-15 16:54:07,169 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_history_summary_info():4064] rendering history
2025-04-15 16:54:07,169 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_history_summary_info():4064] rendering history
2025-04-15 16:54:07,170 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_history_summary_info():4096] rendering summary
2025-04-15 16:54:07,170 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_history_summary_info():4096] rendering summary
2025-04-15 16:54:07,170 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_sync_info():4025] logging synced files
2025-04-15 16:54:07,170 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_footer_sync_info():4025] logging synced files
2025-04-15 16:54:07,171 INFO    Thread-3 (_run_job):1042230 [wandb_run.py:_finish():2189] finishing run ns24z274-iitm-ac-in/finetune_partB_Assgn2/67or1yn3
2025-04-15 16:54:09,171 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:15,274 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 3e8agx0o errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 126, in train
    outputs = model(images)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 285, in forward
    return self._forward_impl(x)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 273, in _forward_impl
    x = self.layer1(x)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 158, in forward
    identity = self.downsample(x)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/functional.py", line 2438, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.65 GiB total capacity; 1.08 GiB already allocated; 37.12 MiB free; 1.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:19,276 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:23,213 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 84qexctq errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 1.16 GiB already allocated; 19.12 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:25,214 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:28,694 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 8mkubxqt errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 1.17 GiB already allocated; 9.12 MiB free; 1.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:30,695 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:34,067 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run s3mdpbum errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:36,067 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:39,487 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run dr0ds16h errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:41,488 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:44,911 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run kp3zrg12 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:47,912 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:51,594 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run en12s2m8 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:53,595 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:54:57,059 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run czqoh64m errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:54:59,060 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:03,196 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 9qias3jf errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 3.12 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:04,197 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:08,862 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 77loqe27 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 119, in train
    outputs = model(images)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 285, in forward
    return self._forward_impl(x)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 276, in _forward_impl
    x = self.layer4(x)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torchvision/models/resnet.py", line 147, in forward
    out = self.bn1(out)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/functional.py", line 2438, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 23.65 GiB total capacity; 3.72 GiB already allocated; 10.69 MiB free; 3.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:09,862 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:14,139 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run gz0f7jug errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:16,140 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:19,748 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run buxqajcl errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:21,748 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:25,289 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run gedvvi62 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:27,291 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:31,345 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run ycepzqt8 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:32,345 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:35,621 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 7w0siway errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:38,623 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:42,652 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run i2dew4n8 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:43,652 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:47,814 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run bbmyqomk errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:49,815 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:53,145 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run p68oesn1 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:55:55,147 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:55:59,179 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run uk0a54ts errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:01,180 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:04,611 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run hsb4h0qn errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:06,613 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:09,868 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run pf0h8ula errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:12,870 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:16,264 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 9iwaycfc errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:18,264 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:21,685 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run vyk2vedr errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:23,686 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:27,141 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run il13dvds errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:30,143 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:33,479 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run zom9zr1d errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:35,480 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:39,102 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run lxt50jiw errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:41,103 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:44,516 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run ia9czjwa errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:46,514 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:49,840 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run awy2ye9q errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:51,841 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:56:55,502 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 10od9lk2 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:56:57,503 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:01,064 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 74b0fd7b errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:03,065 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:06,504 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 7crdvzhq errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:09,506 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:12,794 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 13efrkpg errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:14,795 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:18,247 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run pqr67n8g errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:21,249 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:25,255 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 8zojltfs errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:27,256 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:30,747 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run ajmrvg0c errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:32,747 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:36,227 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 0mj8f5m9 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:38,228 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:41,613 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run sy8qencf errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:44,614 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:48,097 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run uwvtdoyh errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:50,098 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:54,172 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run q9u0f92o errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:57:55,173 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:57:58,534 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run qhl5mo9l errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:01,537 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:04,829 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run xfsm9iq1 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:06,829 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:10,798 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run qd6kx980 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:12,799 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:16,320 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run znn1uzak errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:18,321 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:22,284 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run gfiz99ta errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:24,285 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:28,301 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run k0tbjkn1 errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:30,302 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:34,464 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 84bxijwl errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:35,464 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:39,567 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run bok1mrcp errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:41,568 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:44,958 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run 10w0sxic errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:46,959 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-04-15 16:58:50,275 ERROR   MainThread:1042230 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run sp82lrkl errored:
Traceback (most recent call last):
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_sweep.py", line 19, in sweep_train
    train(args)
  File "/home/speech/da6401/A2/mod_17a/GIT/da6401_assignment2/partB/the_trainer.py", line 94, in train
    model.to(device)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/speech/.conda/envs/dl_things/lib/python3.10/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 4.69 MiB free; 3.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-04-15 16:58:51,275 INFO    MsgRouterThr:1042230 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
